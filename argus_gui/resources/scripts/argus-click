#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import absolute_import
import yaml
# from six.moves import map
import os
import sys

import pyglet
from pyglet import gl
from pyglet.gl import Config
from pyglet import shapes
from pyglet.window import key, mouse
from pyglet.graphics import *
from pyglet.math import Mat4
from pyglet.image import ImageData
#from pygarrayimage.arrayimage import ArrayInterfaceImage

from argus_gui import ArgusColors, FrameFinder, ClickerProject
from argus_gui.tools import *
from argus_gui.arrayImage import ArrayInterfaceImage

import itertools
import math
import pandas
import argus.ocam
# import matplotlib
from PySide6.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget
from PySide6.QtCore import Qt
import pyqtgraph as pg
import pyqtgraph.opengl as pyqt_gl
import ctypes
from scipy.sparse import csc_matrix, lil_matrix
import time
import numpy as np
import copy

from PySide6 import QtWidgets, QtCore

colors = ArgusColors()
colors = colors.getPygletColors()

colors = [(u[0], u[1], u[2], 180) for u in colors]

# Define the colors we will use in RGBA format
CAROLINA_BLUE = (153, 186, 221, 255)  # Go Tar Heels!
MARKER_COLOR = (255, 105, 180, 200)


class GoToPopupWindow(QtWidgets.QDialog):
    """Popup window for skipping to specified frame
    """
    def __init__(self, number_of_frames, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Enter frame number")
        layout = QtWidgets.QVBoxLayout(self)
        self.go_to_frame = QtWidgets.QSpinBox()
        self.go_to_frame.setValue(current_frame)
        self.go_to_frame.setMaximum(number_of_frames)
        layout.addWidget(self.go_to_frame)
        self.label = QtWidgets.QLabel(f'out of {number_of_frames}')
        layout.addWidget(self.label)
        button = QtWidgets.QPushButton("Ok")
        button.clicked.connect(self.accept)
        layout.addWidget(button)
    
    def showEvent(self, event):
        super().showEvent(event)
        self.go_to_frame.setFocus()
        self.go_to_frame.selectAll()

class YesNoPopup(QtWidgets.QWidget):
    def __init__(self, question):
        super().__init__()

        reply = QtWidgets.QMessageBox.question(self, "Question", question, QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.No)

        if reply == QtWidgets.QMessageBox.Yes:
            self.reply = "Yes"
        else:
            self.reply = "No"

class OpenFilePopup(QtWidgets.QWidget):
    def __init__(self, win_title, init, filt):
        super().__init__()
        self.filename, _ = QtWidgets.QFileDialog.getOpenFileName(self, caption = win_title, dir = init, filter = filt)

class SaveFilePopup(QtWidgets.QWidget):
    def __init__(self, win_title, init, filt):
        super().__init__()
        self.filename, _ = QtWidgets.QFileDialog.getSaveFileName(self, caption=win_title, dir = init, filter = filt)

def load_camera(filename):
    global camera_profile
    global camera_filename
    if filename:
        camera_profile = np.loadtxt(filename)
        # Pinhole distortion
        if camera_profile.shape[1] == 12:
            # Format the camera profile to how SBA expects it
            # i.e. take out camera number column, image width and height, then add in skew.
            camera_profile = np.delete(camera_profile, [0, 2, 3, 6], axis=1)

        # CMei's omnidirectional distortion model
        # Citation: http://www.robots.ox.ac.uk/~cmei/articles/single_viewpoint_calib_mei_07.pdf
        elif camera_profile.shape[1] == 13:
            new_list = []
            camera_number_checker = 1
            for profile in camera_profile:
                try:
                    if profile[0] != camera_number_checker:
                        QtWidgets.QMessageBox.warning(None,
                            "Error",
                            "Camera indexes are either not correctly formatted or non-existence"
                        )
                    # Remove the camera index
                    profile = np.delete(profile, [0])

                    # build the list of CMeiUndistorter objects (can't replace them in place as the original
                    # array is numpy and won't accept varying type
                    new_list.append(argus.ocam.CMeiUndistorter(argus.ocam.ocam_model.from_array(profile)))
                    camera_number_checker += 1
                # TODO: Better Error Handling
                except Exception as e:
                    print(e)
                    QtWidgets.QMessageBox.warning(None,
                        "Error",
                        "Could not load Camera profile!"
                    )
                    return
            camera_profile = new_list


        # Scaramuzza's omnidirectional distortion model
        # Citation: http://rpg.ifi.uzh.ch/docs/omnidirectional_camera.pdf
        else:
            new_list = []
            camera_number_checker = 1 
            for profile in camera_profile:
                try:
                    if profile[0] != camera_number_checker:
                        QtWidgets.QMessageBox.warning(None,
                            "Error",
                            "Camera indexes are either not correctly formatted or non-existent"
                        )
                        return
                    # Remove the camera index
                    profile = np.delete(profile, [0])

                    # build the list of PointUndistorter objects (can't replace them in place as the original
                    # array is numpy and won't accept varying type
                    new_list.append(argus.ocam.PointUndistorter(argus.ocam.ocam_model.from_array(profile)))
                    camera_number_checker += 1
                # TODO: Better Error Handling
                except Exception as e:
                    print(e)
                    QtWidgets.QMessageBox.warning(None,
                        "Error",
                        "Could not load Camera profile!"
                    )
                    return
            camera_profile = new_list
        camera_filename = filename

class OptionsPopupWindow(QtWidgets.QDialog):
    """# popup window for the options dialog
    """

    def __init__(self, sync, auto, track_list, track, disp, bstrap, o_sparse, rgb, radius, thickness, parent=None):

        super().__init__(parent)
        self.setWindowTitle("Options")

        self.o_sparse = o_sparse
        self.rgb = rgb
        self.track_list = track_list

        self.cam_entry = QtWidgets.QLineEdit()
        self.lc = QtWidgets.QPushButton('Load camera profile')
        self.lc.clicked.connect(self.load_camera)
        
        self.dlt = QtWidgets.QLineEdit()
        self.ld = QtWidgets.QPushButton('Load DLT coefficients')
        self.ld.clicked.connect(self.load_DLT)

        self.tracks = QtWidgets.QComboBox()
        self.tracks.addItems(track_list)
        self.track = track
        self.tracks.setCurrentText(self.track)

        self.add_button = QtWidgets.QPushButton("Add a new track")
        self.add_button.clicked.connect(self.newTrack)

        self.disp = QtWidgets.QCheckBox("Display all tracks")
        self.disp.setChecked(disp)

        self.sync = QtWidgets.QCheckBox("Keep all videos in same frame")
        self.sync.setChecked(sync)

        self.auto = QtWidgets.QCheckBox("Automatically advance frames")
        self.auto.setChecked(auto)

        self.radius_label = QtWidgets.QLabel("Marker radius")
        self.radius = QtWidgets.QSpinBox()
        self.radius.setValue(radius)
        self.thickness_label = QtWidgets.QLabel("Track line thickness")
        self.thickness = QtWidgets.QSpinBox()
        self.thickness.setValue(thickness)

        self.bstrap = QtWidgets.QCheckBox("Save 95% CIs, spline filtering weights,\nand error tolerance")
        self.bstrap.setChecked(bstrap)

        self.formatlabel = QtWidgets.QLabel("Save format: ")
        self.formatbox = QtWidgets.QComboBox()
        self.formatbox.addItems(["Dense .csv", "Sparse .tsv"])
        self.formatbox.currentIndexChanged.connect(self.sparse_toggle)
        if self.o_sparse:
            self.formatbox.setCurrentText("Sparse .tsv")
        else:
            self.formatbox.setCurrentText("Dense .csv")

        self.colorlabel = QtWidgets.QLabel("Display: ")
        self.colorbox = QtWidgets.QComboBox()
        self.colorbox.addItems(['RGB color', 'grayscale'])
        self.colorbox.currentIndexChanged.connect(self.color_toggle)
        if self.rgb:
            self.colorbox.setCurrentText('RGB color')
        else:
            self.colorbox.setCurrentText('grayscale')

        self.savelabel = QtWidgets.QLabel("Save location/tag: ")
        self.fnam = QtWidgets.QLineEdit()
        self.save_button = QtWidgets.QPushButton('Specify')
        self.save_button.clicked.connect(self.save_as)

        self.okbutton = QtWidgets.QPushButton("Ok")
        self.okbutton.clicked.connect(self.accept)
        
        # set values to globals if they are already set
        self.cam_entry.setText(camera_filename)
        self.dlt.setText(dlt_filename)
        self.fnam.setText(global_filename)
        
        # GUI structure
        genlabel = QtWidgets.QLabel("General Settings")
        displabel = QtWidgets.QLabel("Display options")
        outlabel = QtWidgets.QLabel("Save Settings")
        divider1 = QtWidgets.QFrame()
        divider1.setFrameShape(QtWidgets.QFrame.HLine)
        divider1.setFrameShadow(QtWidgets.QFrame.Sunken)
        divider2 = QtWidgets.QFrame()
        divider2.setFrameShape(QtWidgets.QFrame.HLine)
        divider2.setFrameShadow(QtWidgets.QFrame.Sunken)        

        layout = QtWidgets.QGridLayout(self)
        layout.addWidget(genlabel, 0, 0)
        layout.addWidget(self.cam_entry, 1, 0, 1, 2)
        layout.addWidget(self.lc, 1, 2)
        layout.addWidget(self.dlt, 2, 0, 1, 2)
        layout.addWidget(self.ld, 2, 2)
        layout.addWidget(self.tracks, 3, 0)
        layout.addWidget(self.add_button, 3, 1)

        layout.addWidget(divider1, 4, 0, 1, 3)
        layout.addWidget(displabel, 5, 0, 1, 3)
        layout.addWidget(self.disp, 6, 0)
        layout.addWidget(self.auto, 7, 0)
        layout.addWidget(self.sync, 8, 0)
        layout.addWidget(self.radius_label, 8, 1)
        layout.addWidget(self.radius, 8, 2)
        layout.addWidget(self.colorlabel, 9, 0)
        layout.addWidget(self.colorbox, 9, 0, QtCore.Qt.AlignRight)
        layout.addWidget(self.thickness_label, 9, 1)
        layout.addWidget(self.thickness, 9, 2)
        
        layout.addWidget(divider2, 10, 0, 1, 3)
        layout.addWidget(outlabel, 11, 0, 1, 3)
        layout.addWidget(self.bstrap, 12, 0)
        layout.addWidget(self.formatlabel, 13, 0)
        layout.addWidget(self.formatbox, 13, 0, QtCore.Qt.AlignRight)
        layout.addWidget(self.savelabel, 14, 0)
        layout.addWidget(self.fnam, 15, 0, 1, 2)
        layout.addWidget(self.save_button, 15, 2)
        layout.addWidget(self.okbutton, 16, 2)

        # self.track_list = track_list
        # self.dlts = list()

    # close with Return key
    def keyPressEvent(self, event):
        if event.key() == QtCore.Qt.Key_Return:
            self.accept()

    # popup window for inputting track name
    def newTrack(self):
        track_name_window = newTrackPopup(self)
        if track_name_window.exec() == QtWidgets.QDialog.Accepted:
            new_name = track_name_window.line_edit.text()

        # check to make sure the track name is not empty and does not already exist
        if new_name != '' and new_name not in self.track_list:
            self.track_list.append(new_name)
            self.tracks.addItem(new_name)
            self.tracks.setCurrentText(new_name)

        else:
            QtWidgets.QMessageBox.warning(None,
                "Error",
                "Track names must be unique and non-empty"
            )

    def load_camera(self):
        filename, _ = QtWidgets.QFileDialog.getOpenFileName(self, "Choose camera profile", filter="Text files (*.txt)")
        try:
            if filename:
                load_camera(filename)
                self.cam_entry.setText(filename)
        except:
            QtWidgets.QMessageBox.warning(None,
                "Error",
                "Could not load Camera profile!"
            )

    def load_DLT(self):
        global DLTCoefficients
        global dlt_filename
        filename, _ = QtWidgets.QFileDialog.getOpenFileName(self, "Choose DLT coefficients file", filter="CSV files (*.csv)")

        if filename:
            try:
                DLTCoefficients = np.loadtxt(filename, delimiter=',')
                DLTCoefficients = DLTCoefficients.T
                self.dlt.setText(filename)
                dlt_filename = filename
            # TODO: Better Exception Handling
            except:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Could not load DLT coefficients!"
                )
            
    def sparse_toggle(self):
        if self.formatbox.currentText() == "Sparse .tsv":
            self.o_sparse = True
        elif self.formatbox.currentText() == "Dense .csv":
            self.o_sparse = False

    def color_toggle(self):
        if self.colorbox.currentText() == "RGB color":
            self.rgb == True
        elif self.colorbox.currentText() == "grayscale":
            self.rgb == False

    def save_as(self):
        global global_filename
        filename, _ = QtWidgets.QFileDialog.getSaveFileName(self, "Select location and enter file name prefix")
        if filename != '':
            self.fnam.setText(filename)
            global_filename = filename

class newTrackPopup(QtWidgets.QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Name the new track")
        layout = QtWidgets.QVBoxLayout(self)
        self.line_edit = QtWidgets.QLineEdit()
        layout.addWidget(self.line_edit)
        button = QtWidgets.QPushButton("Ok")
        button.clicked.connect(self.accept)
        layout.addWidget(button)

def draw_circle(coordinates, radius, color = (255, 255, 255, 255), batch = None):
    # coordinates should be passed in as a tupple of (x1, y1)
    x = coordinates[0]
    y = coordinates[1]
    return shapes.Circle(
                x, y, radius,
                color = color,
                batch = batch
    )
    
def draw_line(pt1, pt2, color=(255, 255, 255, 255), width = None, batch=None):
    global thickness
    if width == None:
        width = thickness
    # pt1 and pt2 are tuples or arrays like (x, y) for the two ends of the line
    (x1, y1) = pt1
    (x2, y2) = pt2
    return shapes.Line(
        x1, y1, x2, y2,
        width = width,
        color = color,
        batch = batch
    )


# global variables for options and current track
# all windows pay attention to and modify these
# set to defaults
track_list_global = ['Track 1']
current_track_global = 'Track 1'
auto_advance = True
sync = False
displaying_all_tracks = False
current_frame = 1
common = dict()
load_data_global = None
no_cameras_global = 0
DLTCoefficients = None
camera_profile = None
bstrap = False
busy = False
outputSparse = False
global_filename = ''
rgb = True
vx = 15
vy = 15
# vf = 30
radius = 3
thickness = 3

dlt_filename = ''
camera_filename = ''

# Zooming constants
ZOOM_IN_FACTOR = 1.2
ZOOM_OUT_FACTOR = 1 / ZOOM_IN_FACTOR


# called once to load the CSV into a numpy array a populate the track list, expects a header
def load_csv(csv):
    global load_data_global
    global no_cameras_global
    global track_list_global
    global current_track_global

    # sys.stdout.flush()

    # try:
    track_csv = open(csv)
    header = track_csv.readline()
    new_tracks = []
    header = header.split(',')
    for st in header:
        if st.rsplit('_', 3)[0] not in new_tracks:
            new_tracks.append(st.rsplit('_', 3)[0])

    track_csv.close()

    track_list_global = new_tracks
    current_track_global = track_list_global[0]

    # sys.stdout.flush()
    load_data_global = np.array(pandas.read_csv(csv, index_col=False).values, dtype=np.float16)
    load_data_global[np.isnan(load_data_global)] = 0
    load_data_global = csc_matrix(load_data_global, dtype = np.float32) # this line is failing for some reason but works in tests
    #   File "/Users/jacksonbe3/miniconda3/envs/newPyglet/lib/python3.11/site-packages/scipy/sparse/_coo.py", line 374, in _coo_to_compressed
#     coo_tocsr(M, N, nnz, major, minor, self.data, indptr, indices, data)
# ValueError: Output dtype not compatible with inputs.

    no_cameras_global = len([u for u in pyglet.app.windows if type(u) != GhostWindow])

    # TODO: Better Exception Handling
    # except:
    #     QtWidgets.QMessageBox.warning(None,
    #         "Error",
    #         "Could not load CSV! Make sure it is formatted according to the documentation."
    #     )
    # sys.stdout.flush()


# for sparse data files as TSVs
def load_tsv(tsv):
    global load_data_global
    global no_cameras_global
    global track_list_global
    global current_track_global

    try:
        # load the file, expects a header
        csv_data = pandas.read_csv(tsv, index_col=False, sep='\t', skiprows=1)
        # read into numpy array
        load_data_global = np.zeros((int(list(csv_data.keys())[0]), int(list(csv_data.keys())[1])), dtype=np.float16)
        csv_data = csv_data.values
        for k in range(len(csv_data)):
            load_data_global[int(csv_data[k, 0]) - 1, int(csv_data[k, 1]) - 1] = csv_data[k, 2]

        # convert to compressed sparse matrix form
        load_data_global = csc_matrix(load_data_global)

        no_cameras_global = len([u for u in pyglet.app.windows if type(u) != GhostWindow])

        track_list_global = list()
        for k in range(int(load_data_global.shape[1] / (2 * no_cameras_global))):
            track_list_global.append('Track ' + str(k + 1))

        current_track_global = track_list_global[0]
    except:
        QtWidgets.QMessageBox.warning(None,
            "Error",
            "Could not load TSV! Make sure it is formatted according to the documentation."
        )


# TODO: Implement abstract classes

# main class which displays the movie's individual frames and allows users to mark points
class ClickerWindow(pyglet.window.Window):
    def __init__(self, movie, offsets, actual_camera_number, end, factor, last=False):
        config = Config(double_buffer=True)
        self.actual_camera_number = actual_camera_number
        self.original_index = actual_camera_number - 1

        # Function for converting openCV images to pyglt compatible frames
        self.frameFinder = FrameFinder(movie, factor=factor, offset=offsets[self.original_index], rgb=rgb)

        super(ClickerWindow, self).__init__(width=int(float(self.frameFinder.ow) / factor),
                                            height=int(float(self.frameFinder.oh) / factor), visible=True,
                                            resizable=True, vsync=True)

        self.projection = Mat4.orthogonal_projection(0, int(float(self.frameFinder.ow) / factor), 0 , int(float(self.frameFinder.oh) / factor), -255, 255)
               
        self.movie = movie
        self.offsets = offsets

        self.end = end
        self.points = {}
        self.current_point_index = 1
        self.displayingFrameNumber = True
        self.displayingDLTLines = False
        self.set_caption('{0} - Frame {1} - Track: {2}'.format(movie.split('/')[-1], 1, current_track_global))
        self.folder = ''
        self.current_marker = None
        self.scale_factor = factor

        # create array to keep track of offset changes
        self.offsets_output = np.zeros(self.end)
        self.offsets_output[:] = np.nan

        if self.actual_camera_number == 1:
            self.base = True
        else:
            self.base = False

        self.trackingColors = list()
        self.previous = list()
        self.autoTracking = False

        # batches for fast drawing
        self.main_batch = pyglet.graphics.Batch()
        self.track_batch = pyglet.graphics.Batch()
        self.background = pyglet.graphics.Group(order=0)
        self.dlt_batch = pyglet.graphics.Batch()
        # img is array format from cv2
        img = self.frameFinder.getFrame(1)
    
        #testing pyglet format
        self.img = self.numpy_to_pyglet_image(img)
        
        # commented for testing
        # if img is not None:
        #     # self.img = pyglet.sprite.Sprite(ArrayInterfaceImage(img).get_texture())
        #     self.img = pyglet.sprite.Sprite(img, x=0, y=0)
        #     self.img.x = 0
        #     self.img.y = 0
        #     self.img.scale = float(self.scale_factor)
        # else:
        #     self.img = None
        
        # current mouse coordinate for getting a zoomed view finder
        self.x = 0
        self.y = 0
        # self.view = Mat4()
        # self.initial_view = Mat4(self.view)
        # self.zoom_factor = 4
        # self.viewfinder_zoomed_size = vx * self.zoom_factor
        # #intialize viewfinder window
        # self.viewfinder_window = pyglet.window.Window(
        #     width=vx,
        #     height=vy,
        #     resizable=False,
        #     style=pyglet.window.Window.WINDOW_STYLE_BORDERLESS
        # )
        # self.viewfinder_window.set_location(int(vx/2), int(vy/2))
        
        # modifiable boolean for showing the zoomed view finder
        self.show_view = True

        # dictionaries for storing OpenGL vertices and deleting later if needed
        self.drawn_points = {}
        self.drawn_lines = {}
        self.drawn_dlt = []

        # Initialize camera values
        self.left = 0
        self.right = self.frameFinder.ow
        self.bottom = 0
        self.top = self.frameFinder.oh
        self.zoom_level = 1
        self.zoomed_width = self.frameFinder.ow
        self.zoomed_height = self.frameFinder.oh

        self.update_tracks()

        self.changed = False

        self.vf = int(np.round(self.frameFinder.oh / (vx * 3.)))

    # convert numpy array to pyglet image format
    def numpy_to_pyglet_image(self, frame):
        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_LINEAR)
        height, width, channels = frame.shape
        img_data = frame.tobytes()
        print("HERE", height, width, self.height, self.width)
        return ImageData(width, height, 'RGB', img_data, pitch = width * 3)
    
    # only called upon loading a CSV. Pretty slow to define tons of vertices.
    def draw_tracks(self):
        global radius
        self.update_tracks()
        track = current_track_global
        positions = self.points[track].toarray()
        non_zeros = list(set(self.points[track].nonzero()[0]))

        if self.current_point_index - 1 in non_zeros:
            self.current_marker = draw_circle(
                positions[self.current_point_index - 1],
                radius + 4,
                color = MARKER_COLOR,
                batch = self.track_batch
            )

        for non_zero_value in non_zeros:
            self.drawn_points[track][non_zero_value] = draw_circle(
                positions[non_zero_value],
                radius,
                color = colors[track_list_global.index(track) % len(colors)],
                batch = self.track_batch
            )

        for non_zero_value in non_zeros:
            if non_zero_value + 1 in non_zeros:
                self.drawn_lines[track][non_zero_value] = draw_line(
                        positions[non_zero_value],
                        positions[non_zero_value+1],
                        color = colors[track_list_global.index(track) % len(colors)],
                        batch = self.track_batch                        
                        )

        if displaying_all_tracks:
            for track in self.points.keys():
                if track != current_track_global:
                    positions = self.points[track]
                    non_zeros = list(set(self.points[track].nonzero()[0]))
                    for non_zero_value in non_zeros:
                        if non_zero_value + 1 in non_zeros:
                            self.drawn_lines[track][non_zero_value] = draw_line(
                                    positions[non_zero_value].toarray()[0],
                                    positions[non_zero_value+1].toarray()[0],
                                    color = colors[track_list_global.index(track) % len(colors)],
                                    batch = self.track_batch                        
                                )
                            
    # called when the user decides to display all the tracks
    def draw_all_tracks(self):
        self.update_tracks()
        for track in self.points.keys():
            positions = self.points[track].toarray()
            nz = list(set(self.points[track].nonzero()[0]))

            if track != current_track_global:
                for k in nz:
                    if k + 1 in nz:
                        self.drawn_lines[track][k] = draw_line(
                                    positions[k],
                                    positions[k+1],
                                    color = colors[track_list_global.index(track) % len(colors)],
                                    batch = self.track_batch                        
                            )

    # called when the user decides not to display all the tracks
    def delete_all_tracks(self):
        for track in self.points.keys():
            if track != current_track_global:
                for k in range(len(self.drawn_points[track])):
                    if self.drawn_points[track][k] is not None:
                        self.drawn_points[track][k].delete()
                        self.drawn_points[track][k] = None

                for k in range(len(self.drawn_lines[track])):
                    if self.drawn_lines[track][k] is not None:
                        self.drawn_lines[track][k].delete()
                        self.drawn_lines[track][k] = None

    # called when the user changes tracks
    def change_track(self, old_track):
        #radius = 2
        global radius
        for k in range(len(self.drawn_points[old_track])):
            if self.drawn_points[old_track][k] is not None:
                self.drawn_points[old_track][k].delete()
                self.drawn_points[old_track][k] = None

        if not displaying_all_tracks:
            for k in range(len(self.drawn_lines[old_track])):
                if self.drawn_lines[old_track][k] is not None:
                    self.drawn_lines[old_track][k].delete()
                    self.drawn_lines[old_track][k] = None

        positions = self.points[current_track_global]
        nz = list(set(self.points[current_track_global].nonzero()[0]))

        if self.current_marker is not None:
            self.current_marker.delete()
            self.current_marker = None

        if self.current_point_index - 1 in nz:
            self.current_marker = draw_circle(
                positions[self.current_point_index - 1].toarray()[0], radius + 4, 
                color = MARKER_COLOR,
                batch = self.track_batch
            )
            
        for k in nz:
            self.drawn_points[current_track_global][k] = draw_circle(
                positions[k].toarray()[0], radius, 
                color = colors[track_list_global.index(current_track_global) % 4], 
                batch = self.track_batch
            )

        if not displaying_all_tracks:
            for k in nz:
                if k + 1 in nz:
                    self.drawn_lines[current_track_global][k] = draw_line(
                        positions[k],
                        positions[k+1],
                        color = colors[track_list_global.index(current_track_global) % 4],
                        batch = self.track_batch                        
                        )

    def on_mouse_drag(self, x, y, dx, dy, buttons, modifiers):
        """Allows the user to drag around the current frame
        It's worth noting that in the BaseWindow class (a distant parent of this class) the function
        on_mouse_drag takes : x, y, dx, dy, buttons, modifiers as parameters with x oddly occupying the spot of
        self. However, in practice, all 6 parameters are passed, meaning that function signature simply can't be
        reimplemented.

        :param x: The current X value
        :param y: The current Y value
        :param dx: The distance the mouse was moved horizontally
        :param dy: The distance the mouse was moved vertically
        :param buttons: The buttons used in the drag
        :param modifiers: // TODO Better doc.
        :return: None
        """
        # Move camera
        if modifiers & key.MOD_SHIFT:
            left = self.left - dx * self.zoom_level
            right = self.right - dx * self.zoom_level
            bottom = self.bottom - dy * self.zoom_level
            top = self.top - dy * self.zoom_level

            if left >= 0 and bottom >= 0 and right <= self.frameFinder.ow and top <= self.frameFinder.oh:
                self.left, self.right, self.bottom, self.top = left, right, bottom, top
                self.frameFinder.update(self.left, self.bottom, self.right - self.left, self.top - self.bottom)

    # draw a new point
    def draw_new_point(self, x, y):
        global radius
        track = current_track_global

        new_point_index = self.current_point_index - 1
        old_point_index = self.current_point_index - 2

        self.points[current_track_global][new_point_index] = np.array([x, y])
        self.offsets_output[new_point_index] = self.offsets[self.original_index]

        # Get the numpy array from the sparse csc_matrix representing the coordinate plane
        # with the bottom left corner as the center
        positions = self.points[track].toarray()

        # Note the extra [0] at the end is because numpy returns ([], ) when nonzero is called
        non_zero_points = set(self.points[track].nonzero()[0])

        # If a point already exists in the new slot
        if self.drawn_points[track][new_point_index] is not None:
            self.drawn_points[track][new_point_index].delete()

        self.drawn_points[track][new_point_index] = draw_circle(
                positions[new_point_index], radius, 
                color = colors[track_list_global.index(track) % len(colors)], 
                batch = self.track_batch
            )

        if new_point_index >= 0:
            # Draws a line from the current point to the previous point
            if old_point_index in non_zero_points:
                point_list = (positions[old_point_index], positions[new_point_index])
                if self.drawn_lines[track][old_point_index] is not None:
                    self.drawn_lines[track][old_point_index].delete()
                    self.drawn_lines[track][old_point_index] = draw_line(
                                                                point_list[0],
                                                                point_list[1],
                                                                color = colors[
                                                                             track_list_global.index(track) % len(
                                                                                 colors)
                                                                             ],
                                                                batch = self.track_batch)
                else:
                    self.drawn_lines[track][old_point_index] = draw_line(
                                                                point_list[0],
                                                                point_list[1],
                                                                color = colors[
                                                                             track_list_global.index(track) % len(
                                                                                 colors)
                                                                             ],
                                                                batch = self.track_batch)

            # Draws a line to points ahead of the current one
            if self.current_point_index in non_zero_points and positions[self.current_point_index][0] != 0:
                point_list = (positions[new_point_index], positions[self.current_point_index])
                if self.drawn_lines[track][new_point_index] is not None:
                    self.drawn_lines[track][new_point_index].delete()
                self.drawn_lines[track][new_point_index] = draw_line(
                                                                point_list[0],
                                                                point_list[1],
                                                                color = colors[
                                                                             track_list_global.index(track) % len(
                                                                                 colors)
                                                                             ],
                                                                batch = self.track_batch)
        
        self.change_marker()

    def change_marker(self):
        #  updates current marker with highlight
        global radius
        self.update_tracks()
        track = current_track_global

        positions = self.points[track]
        non_zero_points = list(set(self.points[track].nonzero()[0]))

        if self.current_marker is not None:
            self.current_marker.delete()
            self.current_marker = None

        if self.current_point_index - 1 in non_zero_points:
            # self.current_marker = draw_circle(tuple(positions[self.current_point_index - 1]), radius + 4, MARKER_COLOR,
            #                                   self.track_batch)
            self.current_marker = draw_circle(
                positions[self.current_point_index - 1].toarray()[0], radius + 4, 
                color = MARKER_COLOR, 
                batch = self.track_batch
            )

    # delete a point
    def delete_point(self):
        # if self.current_point_index == 1: return
        #
        # self.current_point_index = 0 if self.current_point_index == 1 else self.current_point_index - 1

        track = current_track_global

        last_added_index = self.current_point_index - 1
        second_most_recent_index = self.current_point_index - 2

        # Reset the current marker
        if self.current_marker is not None:
            self.current_marker.delete()
            self.current_marker = None

        if self.drawn_points[track][last_added_index] is not None:
            self.drawn_points[track][last_added_index].delete()
            self.drawn_points[track][last_added_index] = None
        if self.drawn_lines[track][second_most_recent_index] is not None:
            self.drawn_lines[track][second_most_recent_index].delete()
            self.drawn_lines[track][second_most_recent_index] = None
        if self.drawn_lines[track][last_added_index] is not None:
            self.drawn_lines[track][last_added_index].delete()
            self.drawn_lines[track][last_added_index] = None

    # doesn't really get a bezier curve, just draws lines in between 70 points on the distorted epipolar line
    def get_bezier_curve(self, m, b, prof):
        pts = list()
        for k in range(-10, 60):
            pts.append(np.asarray([self.frameFinder.ow * k / 49., m * (self.frameFinder.ow * k / 49.) + b]))

        ret = redistort_pts(np.asarray(pts), prof)
        ret = np.reshape(ret, (len(pts), 2))

        for k in range(len(ret)):
            ret[k] = ret[k]
        return list(ret)

    # fills the batch for epipolar lines, drawn in Carolina Blue. Go tar heels!
    def make_dlt_batch(self, points):
        for k in range(len(points) - 1):
            # t = tuple([points[k], points[k + 1]])
            # draw_line(t, CAROLINA_BLUE, self.dlt_batch)
            # self.drawn_dlt_curve = draw_line(points[k],
            #                              points[k+1],
            #                              color = CAROLINA_BLUE,
            #                              width = 4,
            #                              batch = self.dlt_batch)
            self.drawn_dlt.append(draw_line(points[k],
                    points[k+1],
                    color = CAROLINA_BLUE,
                    width = 4,
                    batch = self.dlt_batch))

    # Zooms in using OpenGL.  Has bounds so that none of the screen ever has blank space
    def on_mouse_scroll(self, x, y, dx, dy):
        # Get scale factor
        f = ZOOM_IN_FACTOR if dy > 0 else ZOOM_OUT_FACTOR if dy < 0 else 1
        # If zoom_level is in the proper range
        if .05 < self.zoom_level * f < 5:

            zoom_level = f * self.zoom_level

            mouse_x = float(x) / self.width
            mouse_y = float(y) / self.height

            mouse_x_in_world = self.left + mouse_x * self.zoomed_width
            mouse_y_in_world = self.bottom + mouse_y * self.zoomed_height

            zoomed_width = f * self.zoomed_width
            zoomed_height = f * self.zoomed_height

            left = mouse_x_in_world - mouse_x * zoomed_width
            right = mouse_x_in_world + (1 - mouse_x) * zoomed_width
            bottom = mouse_y_in_world - mouse_y * zoomed_height
            top = mouse_y_in_world + (1 - mouse_y) * zoomed_height

            # Check bounds 
            if left >= 0 and bottom >= 0 and right <= self.frameFinder.ow \
                    and top <= self.frameFinder.oh and zoomed_width <= self.frameFinder.ow \
                    and zoomed_height <= self.frameFinder.oh:
                self.left, self.right, self.bottom, self.top, self.zoomed_width, self.zoomed_height = left, right, bottom, top, zoomed_width, zoomed_height
                self.zoom_level = zoom_level
                self.frameFinder.update(self.left, self.bottom, self.right - self.left, self.top - self.bottom)

    # uses Hedrick's function to get a slope and intercept for the Epipolar lines
    def get_epipolar_lines(self):
        global DLTCoefficients
        global dlt_filename
        global camera_profile
        global camera_filename

        self.update_tracks()
        coordinates = []
        tmp = []
        dlt_coeff_2 = DLTCoefficients[self.original_index]

        # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
        for window in pyglet.app.windows:
            if isinstance(window, ClickerWindow):
                if self is not window:
                    try:
                        coordinates.append([window.actual_camera_number,
                                            window.points[current_track_global][self.current_point_index - 1].toarray()[0]])
                    except Exception as e:
                        print(e)
        coordinates = sorted(coordinates)
        for coordinate in coordinates:
            # coordinate[1] is [0. 0.] if no point marked
            if np.any(coordinate[1] != 0):
                dlc_coeff_1 = DLTCoefficients[coordinate[0] - 1]
                x_cord = coordinate[1][0]
                y_cord = coordinate[1][1]
                # The coordinate has the first value of the camera
                # Thus the camera profile is indexing at the literal profile for this camera
                if camera_profile is not None:
                    try:
                        _ = undistort_pts(np.asarray([x_cord, y_cord]), camera_profile[coordinate[0] - 1])[0]
                        x_cord = _[0]
                        y_cord = _[1]
                    except np.linalg.LinAlgError as e:
                        QtWidgets.QMessageBox.warning(None,
                            "Error",
                            f"Numpy complained with the following message: \n{e}\n"
                            "This typically indicates a malformed camera profile or incorrect DLT Coefficients\n"
                            "To prevent future dialogs from appearing, DLT Coefficients are going to be set to null. "
                            "If you would like to re-enable this feature, check your profile and coefficents again and reload "
                            "them."
                        )
                        DLTCoefficients = None
                        dlt_filename = ""
                        camera_profile = None
                        camera_filename = ""

                slope, intercept = getDLTLine(x_cord, y_cord, dlc_coeff_1, dlt_coeff_2)
                if camera_profile is None:
                    tmp.append(np.asarray([0, intercept]))
                    tmp.append(np.asarray([self.frameFinder.ow, slope * self.frameFinder.ow + intercept]))
                else:
                    tmp = self.get_bezier_curve(slope, intercept, camera_profile[coordinate[0] - 1])
                self.make_dlt_batch(tmp)

    # makes sure all the dictionaries have the proper keys
    def update_tracks(self):
        for track in track_list_global:
            try:
                self.points[track]
            except KeyError:
                self.points[track] = csc_matrix((self.end, 2))

            try:
                # Checks if the track key exists
                self.drawn_points[track]
                self.drawn_lines[track]
            except KeyError:
                self.drawn_points[track] = list()
                self.drawn_lines[track] = list()
                for k in range(self.points[track].shape[0]):
                    self.drawn_points[track].append(None)
                for k in range(self.points[track].shape[0] - 1):
                    self.drawn_lines[track].append(None)

    #redraws after changing circle radius or line thickness
    def redraw_all(self, rad, thick):
        global radius
        global thickness
        # rad and thick are booleans stating if state changed
        # drawn_points and _lines are dicts - [track][index]
        if rad:
            for track, pts in self.drawn_points.items():
                for k in range(len(pts)):
                    if pts[k] is not None:
                        pts[k].radius = radius                    
        if thick:
            for track, pts in self.drawn_lines.items():
                for k in range(len(pts)):
                    if pts[k] is not None:
                        pts[k].width = thickness
            
        
    # called by each window upon saving.
    # Fills a common dictionary with its tracks which is then written to a CSV using pandas.
    def fill_common_dictionary(self):
        global common

        uvs = dict()
        for track in self.points.keys():
            uvs[track] = copy.copy(self.points[track]).toarray()
            uvs[track][uvs[track] == 0] = np.nan
            common[track + '_cam_' + str(self.actual_camera_number) + '_x'] = uvs[track][:, 0]
            common[track + '_cam_' + str(self.actual_camera_number) + '_y'] = uvs[track][:, 1]

    # called for each window after the common dictionary is filled.
    # probably a more intuitive way to grab parts rather than indexing them
    def load_points(self):
        global load_data_global
        # for each track, load in your points
        matching = True

        # sys.stdout.flush()
        for track in self.points.keys():
            # sys.stdout.flush()
            current_track_index = track_list_global.index(track)
            self.points[track] = load_data_global[:,
                                 2 * current_track_index * no_cameras_global + 2 * self.original_index:
                                 2 * current_track_index * no_cameras_global + 2 * self.original_index + 2]

            if self.points[track].shape[0] > self.end:
                matching = False
        self.clearBatch()
        # sys.stdout.flush()
        start_time = time.time()
        self.draw_tracks()

        return matching

    def update_viewfinder(self):
        try:
            view = self.frameFinder.getViewFinder(self.current_point_index, self.x, self.y, vx, vy, self.vf,
                                                      self.autoTracking)
        except:
                view = None
        if view is not None:
            scale = (((self.right - self.left) * (self.top - self.bottom)) / (
                    self.frameFinder.oh * self.frameFinder.ow)) ** 0.5
            # self.view = pyglet.sprite.Sprite(ArrayInterfaceImage(view).get_texture(),
            #                                     x=self.right - np.floor(vx * self.vf * scale), y=self.bottom)
            # self.view = ArrayInterfaceImage(view).get_texture()
            # self.view.scale = scale
        #     self.
        # zoomed_image = self.imgarr.get_region(
        #     self.x - self.viewfinder_size // 2,
        #     self.y - self.viewfinder_size // 2,
        #     self.viewfinder_size,
        #     self.viewfinder_size
        # ).get_texture()
        # zoomed_image.width = self.viewfinder_zoomed_size
        # zoomed_image.height = self.viewfinder_zoomed_size

        self.viewfinder_window.switch_to()
        self.view.blit(0, 0)

        # Draw the red crosshair
        # glColor3f(1.0, 0.0, 0.0)
        # glBegin(GL_LINES)
        # glVertex2f(self.viewfinder_zoomed_size // 2, 0)
        # glVertex2f(self.viewfinder_zoomed_size // 2, self.viewfinder_zoomed_size)
        # glVertex2f(0, self.viewfinder_zoomed_size // 2)
        # glVertex2f(self.viewfinder_zoomed_size, self.viewfinder_zoomed_size // 2)
        # glEnd()

        self.switch_to()
        
    def on_draw(self):
        self.clear()

        self.projection = Mat4.orthogonal_projection(self.left, self.right, self.bottom, self.top, -255, 255)


        # if self.x != 0 and self.y != 0:
            # self.sprite.draw()
            # self.update_viewfinder()
            # try:
            #     view = self.frameFinder.getViewFinder(self.current_point_index, self.x, self.y, vx, vy, self.vf,
            #                                           self.autoTracking)
        #         # mark discrete estimate with red cross
        #         view[int(view.shape[0] / 2), :] = np.array([255., 0., 0.])
        #         view[:, int(view.shape[1] / 2)] = np.array([255., 0., 0.])
            # except:
            #     view = None
            # if view != self.initial_view:
            #     scale = (((self.right - self.left) * (self.top - self.bottom)) / (
            #             self.frameFinder.oh * self.frameFinder.ow)) ** 0.5
            #     self.view = pyglet.sprite.Sprite(ArrayInterfaceImage(view).get_texture(),
            #                                      x=self.right - np.floor(vx * self.vf * scale), y=self.bottom)
            #     self.view.scale = scale

        if self.current_point_index != current_frame and sync:
            self.current_point_index = current_frame
            
        # If there exists a frame relative to the first camera, display it. else you get a black screen
        # if self.changed:
        #     im = self.frameFinder.getFrame(self.current_point_index)
        #     if im is not None:
        #         if self.img is not None:
        #             self.img.image = ArrayInterfaceImage(im)
        #         else:
        #             self.img = pyglet.sprite.Sprite(ArrayInterfaceImage(im))
        #             self.img.scale = float(self.scale_factor)
        #     else:
        #         self.img = None
        # self.img.blit(0,0, width = self.frameFinder.ow, height = self.frameFinder.oh)
        if self.changed:
            im = self.frameFinder.getFrame(self.current_point_index)
            if im is not None:
                self.img = self.numpy_to_pyglet_image(im)
            else:
                self.img = None
                
        if self.img is not None:
            # self.img.draw()
            self.img.blit(0,0, width = self.frameFinder.ow, height=self.frameFinder.oh)
        # if self.view is not None and self.show_view:
        #     self.view.draw()
        # if DLT coefficients are present, draw epipolar lines in Carolina Blue
        if DLTCoefficients is not None:
            self.dlt_batch = pyglet.graphics.Batch()
            self.get_epipolar_lines()
            self.dlt_batch.draw()
            
        if not busy:
            # if not self.base:
            self.set_caption(
                '{0} - Frame {1}, Offset: {2} - Track: {3}'.format(self.movie.split('/')[-1], self.current_point_index,
                                                                   self.frameFinder.offset, current_track_global))
        else:
            self.set_caption('{0} - Working...'.format(self.movie.split('/')[-1]))

        self.track_batch.draw()
        # self.drawn_lines['test'] = draw_line([1339.44370511, 378.78527146], [1373.30335652, 336.79267411], width = 20, batch = self.dlt_batch)
        

    def tick(self):
        global sync

        if sync:
            sync = False
        if self.autoTracking:
            uv = self.points[current_track_global][self.current_point_index - 2][0].toarray()[0]
            pts = self.points[current_track_global].toarray()

            if self.frameFinder.kf is None:
                nz = sorted(list(set(self.points[current_track_global].nonzero()[0])))
                ind = [self.current_point_index - 2]
                for k in range(20):
                    if self.current_point_index - (3 + k) in nz:
                        ind = [self.current_point_index - (3 + k)] + ind
                    else:
                        break
                if len(ind) >= 2:
                    self.frameFinder.makeKalman(pts[ind])
            if uv[0] != 0:
                try:
                    pos = self.frameFinder.CrossTrack(uv[0] - vx, (self.frameFinder.oh - uv[1]) - vy, 2 * vx, 2 * vy)
                    if self.frameFinder.kf is not None:
                        self.frameFinder.update_kalman(pos)
                except Exception as e:
                    print(e)
                    self.autoTracking = False
                    pyglet.clock.unschedule(up)
                    return
                if not True in np.isnan(pos):
                    self.draw_new_point(pos[0], pos[1])

                self.changed = True
                self.current_point_index += 1
                if sync:
                    self.update_all_windows()
                    # self.updateSelf()
            else:
                self.autoTracking = False
                pyglet.clock.unschedule(up)
                return

    # called to make sure everybody gets the changes made by one window
    def update_all_windows(self):
        # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
        for window in pyglet.app.windows:
            if isinstance(window, ClickerWindow):
                if self is not window:
                    window.switch_to()
                    window.update_tracks()
                    window.dispatch_events()
                    window.dispatch_event('on_draw')
                    window.change_marker()
                    window.flip()

    def dense_to_sparse(self, arr):
        # create a sparse data file with rows and columns indexed by the natural numbers
        # as per MATLAB etiquette
        row = list()
        col = list()
        val = list()
        for k in range(len(arr)):
            for j in range(arr.shape[1]):
                if not np.isnan(arr[k, j]):
                    row.append(k + 1)
                    col.append(j + 1)
                    val.append(arr[k, j])

        out = np.zeros((len(row) + 1, 3))
        out[1:, 0] = np.array(row)
        out[1:, 1] = np.array(col)
        out[1:, 2] = np.array(val)
        out[0, 0] = len(arr)
        out[0, 1] = arr.shape[1]
        out[0, 2] = len(row)
        return out

    def save_sparse(self, save_as=True):
        global global_filename
        filename = ''
        if save_as or global_filename == '':
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = SaveFilePopup("Select location and enter prefix for sparse file", global_filename.split('/')[-1], 'All files (*.*)')
            if w.filename:
                filename = w.filename
        else:
            filename = global_filename
        if filename == '':
            return
        if filename != '' and type(filename) == str:
            global_filename = filename
            # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            for window in pyglet.app.windows:
                if isinstance(window, ClickerWindow):
                    window.fill_common_dictionary()

            offsets_out = list()

            # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            for window in pyglet.app.windows:
                if isinstance(window, ClickerWindow):
                    offsets_out.append(window.offsets_output)

            offsets_out = np.array(offsets_out).T

            # get the header
            cols = sorted(common.keys())
            # stack all the columns together
            _ = common[cols[0]]
            _ = np.reshape(_, (_.shape[0], 1))
            for k in range(1, len(cols)):
                _ = np.hstack((_, np.reshape(common[cols[k]], (_.shape[0], 1))))
            pts = _

            dataf = pandas.DataFrame(self.dense_to_sparse(pts), columns=['Row', 'Column', 'Entry'])
            dataf[['Row', 'Column']] = dataf[['Row', 'Column']].astype(np.uint32)
            dataf.iloc[0].apply(np.uint32)
            if DLTCoefficients is not None and camera_profile is not None:
                # make a data frame for the xyz coordinates for all tracks and all frames
                xyzss = list()
                for j in range(pts.shape[1] // (2 * len(camera_profile))):
                    xyzs = uv_to_xyz(pts[:, j * 2 * len(camera_profile):(j + 1) * 2 * len(camera_profile)],
                                     camera_profile, DLTCoefficients)
                    # cPickle.dump(pts[:,j*2*len(CameraProfile):(j+1)*2*len(CameraProfile)], open('points' + str(j) + '.p', 'wb'))
                    xyzss.append(xyzs)
                xyzss = np.asarray(xyzss)
                _ = xyzss[0]
                for k in range(1, len(xyzss)):
                    _ = np.hstack((_, xyzss[k]))

                dataf1 = pandas.DataFrame(self.dense_to_sparse(_), columns=['Row', 'Column', 'Entry'])
                dataf1[['Row', 'Column']] = dataf1[['Row', 'Column']].astype(np.uint32)
                dataf1.iloc[0].apply(np.uint32)

                # save offsets (always non-sparse)
                datafo = pandas.DataFrame(offsets_out, columns=['camera_{0}'.format(u) for u in range(1, len(
                    [u for u in pyglet.app.windows if type(u) != GhostWindow]) + 1)])
                datafo.to_csv(filename + '-offsets.csv', index=False, na_rep='NaN')

                # get reprojection errors for all 3d points and make a data frame for it
                repoErrs = get_repo_errors(_, pts, camera_profile, DLTCoefficients).T
                dataf2 = pandas.DataFrame(self.dense_to_sparse(repoErrs), columns=['Row', 'Column', 'Entry'])
                dataf2[['Row', 'Column']] = dataf2[['Row', 'Column']].astype(np.uint32)
                dataf2.iloc[0].apply(np.uint32)

                if bstrap:
                    CIs, weights, tols = bootstrapXYZs(pts, repoErrs, camera_profile, DLTCoefficients)
                    upper = _ + CIs
                    lower = _ - CIs

                    _ = np.zeros((upper.shape[0], upper.shape[1] * 2))
                    _[_ == 0] = np.nan
                    for k in range(int(upper.shape[1] / 3)):
                        _[:, 2 * k * 3:2 * (k + 1) * 3] = np.concatenate(
                            (lower[:, k * 3:(k + 1) * 3], upper[:, k * 3:(k + 1) * 3]), axis=1)
                    dataf3 = pandas.DataFrame(self.dense_to_sparse(_), columns=['Row', 'Column', 'Entry'])
                    dataf3[['Row', 'Column']] = dataf3[['Row', 'Column']].astype(np.uint32)
                    dataf3.iloc[0].apply(np.uint32)

                    dataf3.to_csv(filename + '-xyz-cis.tsv', index=False, na_rep='NaN', sep='\t')

                    pandas.DataFrame(self.dense_to_sparse(weights), columns=['Row', 'Column', 'Entry']).to_csv(
                        filename + '-spline-weights.tsv', index=False, na_rep='NaN', sep='\t')
                    # pickle.dump(tols, open('tols.p', 'w'))
                    pandas.DataFrame(self.dense_to_sparse(np.reshape(tols, (1, len(xyz_cols)))),
                                     columns=['Row', 'Column', 'Entry']).to_csv(
                        filename + '-spline-error-tolerances.tsv', index=False, na_rep='NaN', sep='\t')

                # write the data frames to CSV
                dataf1.to_csv(filename + '-xyzpts.tsv', index=False, na_rep='NaN', sep='\t')
                dataf2.to_csv(filename + '-xyzres.tsv', index=False, na_rep='NaN', sep='\t')
            else:
                # for matlab compatibility, make a residual file, even if we can't reproject
                _ = np.zeros((self.end, len(track_list_global)))
                _[:, :] = np.nan
                dataf2 = pandas.DataFrame(_, columns=sorted(track_list_global))
                dataf2.to_csv(filename + '-xyzres.csv', index=False, na_rep='NaN')
            dataf.to_csv(filename + '-xypts.tsv', index=False, na_rep='NaN', sep='\t')
            QtWidgets.QMessageBox.information(None,"Success", f'Write successful! TSVs successfully written to {filename}.')
        return

    def save_non_sparse(self, saveas=True):
        global global_filename
        filename = ''
        if saveas or global_filename == '':
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = SaveFilePopup("Select location and enter prefix for dense file", global_filename.split('/')[-1], 'All files (*.*)')
            if w.filename:
                filename = w.filename
        else:
            filename = global_filename
        if filename == '':
            return
        if filename != '' and type(filename) == str:
            global_filename = filename
            # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            for window in pyglet.app.windows:
                if isinstance(window, ClickerWindow):
                    window.fill_common_dictionary()

            # get the header
            cols = sorted(common.keys())
            # stack all the columns together
            _ = common[cols[0]]
            _ = np.reshape(_, (_.shape[0], 1))
            for k in range(1, len(cols)):
                _ = np.hstack((_, np.reshape(common[cols[k]], (_.shape[0], 1))))
            # make a dataframe from the marked pixel coordinates
            dataf = pandas.DataFrame(_, columns=cols)
            pts = dataf.values

            offsets_out = list()

            # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            for window in pyglet.app.windows:
                if isinstance(window, ClickerWindow):
                    offsets_out.append(window.offsets_output)

            offsets_out = np.array(offsets_out).T

            # save offsets (always non-sparse)
            datafo = pandas.DataFrame(offsets_out, columns=['camera_{0}'.format(u) for u in range(1, len(
                [u for u in pyglet.app.windows if type(u) != GhostWindow]) + 1)])
            datafo.to_csv(filename + '-offsets.csv', index=False, na_rep='NaN')

            # if we have DLT coefficients and intrinsic camera information, triangulate and write the 3D coordinates frame-by-frame
            if DLTCoefficients is not None and camera_profile is not None:
                # make a data frame for the xyz coordinates for all tracks and all frames
                xyzss = list()
                for j in range(int(pts.shape[1] / (2 * len(camera_profile)))):
                    xyzs = uv_to_xyz(pts[:, j * 2 * len(camera_profile):(j + 1) * 2 * len(camera_profile)],
                                     camera_profile, DLTCoefficients)
                    # cPickle.dump(pts[:,j*2*len(CameraProfile):(j+1)*2*len(CameraProfile)], open('points' + str(j) + '.p', 'wb'))
                    xyzss.append(xyzs)
                xyzss = np.asarray(xyzss)
                _ = xyzss[0]
                for k in range(1, len(xyzss)):
                    _ = np.hstack((_, xyzss[k]))

                xyz_cols = list()
                sTracks = sorted(track_list_global)
                for k in range(len(track_list_global)):
                    xyz_cols.append(sTracks[k] + '_x')
                    xyz_cols.append(sTracks[k] + '_y')
                    xyz_cols.append(sTracks[k] + '_z')
                dataf1 = pandas.DataFrame(_, columns=xyz_cols)

                # get reprojection errors for all 3d points and make a data frame for it
                repoErrs = get_repo_errors(_, pts, camera_profile, DLTCoefficients).T
                cols = sorted(track_list_global)
                dataf2 = pandas.DataFrame(repoErrs, columns=cols)

                if bstrap:
                    cols = list()
                    for k in range(len(track_list_global)):
                        cols.append(sTracks[k] + '_x_lower')
                        cols.append(sTracks[k] + '_y_lower')
                        cols.append(sTracks[k] + '_z_lower')
                        cols.append(sTracks[k] + '_x_upper')
                        cols.append(sTracks[k] + '_y_upper')
                        cols.append(sTracks[k] + '_z_upper')

                    CIs, weights, tols = bootstrapXYZs(pts, repoErrs, camera_profile, DLTCoefficients)
                    upper = dataf1.values + CIs
                    lower = dataf1.values - CIs

                    _ = np.zeros((upper.shape[0], upper.shape[1] * 2))
                    _[_ == 0] = np.nan
                    for k in range(upper.shape[1] // 3):
                        _[:, 2 * k * 3:2 * (k + 1) * 3] = np.concatenate(
                            (lower[:, k * 3:(k + 1) * 3], upper[:, k * 3:(k + 1) * 3]), axis=1)
                    dataf3 = pandas.DataFrame(_, columns=cols)
                    dataf3.to_csv(filename + '-xyz-cis.csv', index=False, na_rep='NaN')

                    pandas.DataFrame(weights, columns=xyz_cols).to_csv(filename + '-spline-weights.csv', index=False,
                                                                       na_rep='NaN')
                    # pickle.dump(tols, open('tols.p', 'w'))
                    pandas.DataFrame(np.reshape(tols, (1, len(xyz_cols))), columns=xyz_cols).to_csv(
                        filename + '-spline-error-tolerances.csv', index=False, na_rep='NaN')

                # write the data frames to CSV
                dataf1.to_csv(filename + '-xyzpts.csv', index=False, na_rep='NaN')
                dataf2.to_csv(filename + '-xyzres.csv', index=False, na_rep='NaN')
            else:
                # for matlab compatibility, make a residual file, even if we can't reproject
                _ = np.zeros((self.end, len(track_list_global)))
                _[:, :] = np.nan
                dataf2 = pandas.DataFrame(_, columns=sorted(track_list_global))
                dataf2.to_csv(filename + '-xyzres.csv', index=False, na_rep='NaN')
            dataf.to_csv(filename + '-xypts.csv', index=False, na_rep='NaN')
            QtWidgets.QMessageBox.information(None, "Success", f'Write successful! CSVs successfully written to {filename}')

            settings = {
                "sync": sync,
                "displaying_all_tracks": displaying_all_tracks,
                "current_track": current_track_global,
                "auto_advance": auto_advance,
                "global_filename": global_filename,
                "rgb": rgb,
                "output_sparse": outputSparse,
                "bstrap": bstrap,
                "init_track": track_list_global[0]
            }

            ClickerProject.create(proj_path=filename,
                                  video_paths=movies_global,
                                  points=f"{filename}-xypts.csv",
                                  resolution=self.scale_factor,
                                  last_frame=self.current_point_index,
                                  offsets=f"{filename}-offsets.csv",
                                  dlt_coefficents=dlt_filename if dlt_filename else None,
                                  camera_profile=camera_filename if camera_filename else None,
                                  settings=settings)

    # pretty self explanatory
    def updateSelf(self):
        self.switch_to()
        self.update_tracks()
        self.dispatch_events()
        self.dispatch_event('on_draw')
        self.flip()

    def clearBatch(self):
        self.track_batch = pyglet.graphics.Batch()
        self.drawn_points = dict()
        self.drawn_lines = dict()
        self.drawn_dlt = list()
        return

    # nests potentially long operations to let the user know that the program is working hard
    def toggleBusy(self):
        global busy

        if not busy:
            busy = True
        else:
            busy = False

        self.update_all_windows()
        self.updateSelf()

    # def plotTracks(self):
    #     for window in [u for u in pyglet.app.windows]:
    #         print(type(window))
    #         print(type(window) == 'ClickerWindow')
    def plotTracks(self): #, track_indices=np.arange(len(track_list_global))):
        # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
        for window in pyglet.app.windows:
            if isinstance(window, ClickerWindow):
                window.fill_common_dictionary()
        cols = sorted(common.keys())
        _ = common[cols[0]]
        _ = np.reshape(_, (_.shape[0], 1))
        for k in range(1, len(cols)):
            _ = np.hstack((_, np.reshape(common[cols[k]], (_.shape[0], 1))))
        pts = _

        track_indices = np.arange(len(track_list_global))
        
        app = QtWidgets.QApplication.instance()
        running = True
        if app is None:
            running = False
            # necessary for regraphing after removing outliers using openGL
            QtWidgets.QApplication.setAttribute(Qt.AA_ShareOpenGLContexts)
            app = QtWidgets.QApplication(sys.argv)
            
        
        plotter = TrackPlotter(pts, track_indices, camera_profile, DLTCoefficients, ArgusColors)
        plotter.init_UI()
        plotter.show()
        app.exec()
        # if not running:
        #     app.exec()
        # pyglet.app.run()
        # fig = plt.figure()
        # ax = fig.add_subplot(111, projection='3d')
        # # make a data frame for the xyz coordinates for all tracks and all frames
        # xyzss = list()
        # for j in range(int(pts.shape[1] / (2 * len(camera_profile)))):
        #     xyzs = uv_to_xyz(pts[:, j * 2 * len(camera_profile):(j + 1) * 2 * len(camera_profile)], camera_profile,
        #                      DLTCoefficients)
        #     xyzss.append(xyzs)

        # colors = ArgusColors().getMatplotlibColors()

        # for k in range(len(track_indices)):
        #     xyz = xyzss[track_indices[k]]
        #     x = xyz[:, 0]
        #     y = xyz[:, 1]
        #     z = xyz[:, 2]
        #     ax.plot(x, y, z, color=colors[k % len(colors)])

        # plt.show(block=False)
        # plt.close()

    def deleteTrack(self, track):
        # delete the sparse array of points
        del self.points[track]

        # delete all drawn OpenGL vertices
        for k in range(len(self.drawn_points[track])):
            if self.drawn_points[track][k] is not None:
                self.drawn_points[track][k].delete()

        for k in range(len(self.drawn_lines[track])):
            if self.drawn_lines[track][k] is not None:
                self.drawn_lines[track][k].delete()

        # delete the dictionary keys and lists themselves
        del self.drawn_points[track]
        del self.drawn_lines[track]

    def options_menu(self):
        global sync
        global auto_advance
        global track_list_global
        global current_track_global
        global current_frame
        global load_data_global
        global displaying_all_tracks
        global busy
        global bstrap
        global outputSparse
        global rgb
        global vx
        global vy
        global radius
        global thickness

        self.toggleBusy()

        # make an options window and wait for it

        app = QtWidgets.QApplication.instance()
        if app is None:
            app = QtWidgets.QApplication([])
        w = OptionsPopupWindow(sync, auto_advance, track_list_global, current_track_global, displaying_all_tracks, bstrap, outputSparse, rgb, radius, thickness)
        if w.exec() == QtWidgets.QDialog.Accepted:
            auto_advance = w.auto.isChecked()
            sync = w.sync.isChecked()
            new_disp = w.disp.isChecked()
            bstrap = w.bstrap.isChecked()
            outputSparse = w.o_sparse
            rgb = w.rgb
            rad = False
            thick = False
            #radius changed, redraw all
            if radius != int(w.radius.text()):
                rad = True
                radius = int(w.radius.text())
            # line thickness changed, redraw all
            if thickness != int(w.thickness.text()):
                thick = True
                thickness = int(w.thickness.text())
            if rad or thick:
                self.redraw_all(rad, thick)

            track_list_global = w.track_list

            # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            for window in pyglet.app.windows:
                if isinstance(window, ClickerWindow):
                    window.update_tracks()

            # if the current track changed and the displaying of the rest of the tracks did not
            if current_track_global != w.tracks.currentText() and new_disp == displaying_all_tracks:
                old_track = current_track_global
                current_track_global = w.tracks.currentText()
                # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.change_track(old_track)

            # if the current track changed and the displaying of other tracks was turned on
            elif current_track_global != w.tracks.currentText() and new_disp:
                # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.draw_all_tracks()
                old_track = current_track_global
                current_track_global = w.tracks.currentText()
                displaying_all_tracks = new_disp
                # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.change_track(old_track)

            # if the current track changed and the displaying of other tracks was turned off
            elif current_track_global != w.tracks.currentText():
                old_track = current_track_global
                current_track_global = w.tracks.currentText()
                # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.change_track(old_track)
                        window.delete_all_tracks()

            # if the track did not change but we turned on displaying the rest
            elif new_disp != displaying_all_tracks and new_disp:
                # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.draw_all_tracks()

            # if the track did not change but we turned off the displaying of the rest of tracks
            elif new_disp != displaying_all_tracks and not new_disp:
                # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.delete_all_tracks()

            # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            for window in pyglet.app.windows:
                if isinstance(window, ClickerWindow):
                    window.frameFinder.rgb = rgb
                    im = window.frameFinder.getFrame(window.current_point_index)
                    if im is not None:
                        window.img = pyglet.sprite.Sprite(ArrayInterfaceImage(im).get_texture())
                        window.img.scale = float(self.scale_factor)

            current_track_global = w.tracks.currentText()
            displaying_all_tracks = new_disp

        self.toggleBusy()
        self.update_all_windows()

    def go_to_frame(self, frame):
        global current_frame
        self.current_point_index = frame
        current_frame = self.current_point_index
        self.changed = True
        self.change_marker()

    def on_key_press(self, symbol, modifiers):
        """Manager for hotkeys
        :param symbol: Symbol passed from pyglt (?) representing the key pressed //Todo: Verify
        :param modifiers: // TODO: Document
        :return:
        """
        global sync
        global auto_advance
        global track_list_global
        global current_track_global
        global current_frame
        global load_data_global
        global displaying_all_tracks
        global busy
        global bstrap
        global outputSparse
        global rgb
        global vx
        global vy

        # brings up options dialog
        if symbol == key.O:
            self.options_menu()

        # turns on color-based contour autotracking
        elif symbol == key.A:
            self.frameFinder.destroy_kalman()
            self.frameFinder.track_image = None
            if self.autoTracking:
                self.autoTracking = False
                pyglet.clock.unschedule(up)
            else:
                if self.frameFinder.background_subtract:
                    self.frameFinder.toggleBackGroundSubtract()
                self.autoTracking = True
                pyglet.clock.schedule(up)
        elif symbol == key.V:
            if self.show_view:
                self.show_view = False
            else:
                self.show_view = True
            self.updateSelf()
        # skips one frame ahead
        elif symbol == key.F and (modifiers == 0 or modifiers == 16):
            if self.current_point_index + 1 <= self.end:
                self.changed = True
                self.current_point_index += 1
                current_frame = self.current_point_index
                self.change_marker()
                if sync:
                    self.update_all_windows()
        # skips 50 frames ahead
        elif symbol == key.F and modifiers & key.MOD_SHIFT:
            if self.current_point_index + 50 <= self.end:
                self.changed = True
                self.current_point_index += 50
                current_frame = self.current_point_index
                self.change_marker()
                if sync:
                    self.update_all_windows()
        # skips one frame behind
        elif symbol == key.B and (modifiers == 0 or modifiers == 16):
            if self.current_point_index - 1 > 0:
                self.changed = True
                self.current_point_index -= 1
                current_frame = self.current_point_index
                self.change_marker()
                if sync:
                    self.update_all_windows()
        # skips 50 frames back
        elif symbol == key.B and modifiers & key.MOD_SHIFT:
            if self.current_point_index - 50 > 0:
                self.changed = True
                self.current_point_index -= 50
                current_frame = self.current_point_index
                self.change_marker()
                if sync:
                    self.update_all_windows()
        # for capturing image
        elif symbol == key.C and modifiers & key.MOD_SHIFT:
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = SaveFilePopup("Select location to save captured image", global_filename.split('/')[-1], 'All files (*.*)')
            if w.filename:
                self.folder = w.filename
        elif symbol == key.C and modifiers & key.MOD_ALT:
            if self.folder != '':
                self.frameFinder.capture(self.folder)
            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Must specify a directory before taking snapshots"
                )
                return
        # go to frame
        elif symbol == key.G:
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = GoToPopupWindow(self.end)
            if w.exec() == QtWidgets.QDialog.Accepted:
                try:
                    int(w.go_to_frame.value())
                except:
                    QtWidgets.QMessageBox.warning(None,
                        "Error",
                        "Frame to go to must be a valid integer"
                    )
                    return

            if 1 <= int(w.go_to_frame.value()) <= self.end:
                self.current_point_index = int(w.go_to_frame.value())
                current_frame = self.current_point_index
                self.changed = True
                self.change_marker()
                if sync:
                    self.update_all_windows()

            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Frame out of bounds"
                )
        # changes track to the next one in the list
        elif symbol == key.PERIOD:
            start_time = time.time()

            old_track = current_track_global
            if track_list_global.index(current_track_global) + 1 < len(track_list_global):
                current_track_global = track_list_global[track_list_global.index(current_track_global) + 1]
            else:
                current_track_global = track_list_global[0]
            # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            if current_track_global != old_track:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.change_track(old_track)
                self.update_all_windows()

        # changes track to the previous one in the list
        elif symbol == key.COMMA:
            old_track = current_track_global
            if track_list_global.index(current_track_global) - 1 >= 0:
                current_track_global = track_list_global[track_list_global.index(current_track_global) - 1]
            else:
                current_track_global = track_list_global[-1]
            # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
            if current_track_global != old_track:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.change_track(old_track)
                self.update_all_windows()
        # toggle the display of frame number in the current window
        elif symbol == key.F and modifiers & key.MOD_CTRL:
            if self.displayingFrameNumber:
                self.displayingFrameNumber = False
            else:
                self.displayingFrameNumber = True
        # reset to the original view of the entire frame
        elif symbol == key.R:
            self.left = 0
            self.right = self.frameFinder.ow
            self.bottom = 0
            self.top = self.frameFinder.oh
            self.zoom_level = 1
            self.zoomed_width = self.frameFinder.ow
            self.zoomed_height = self.frameFinder.oh
            self.frameFinder.update(self.left, self.bottom, self.right - self.left, self.top - self.bottom)
        # saving points to a CSV file
        elif symbol == key.S:
            if modifiers & key.MOD_CTRL:
                saveas = True
            else:
                saveas = False

            self.toggleBusy()
            if outputSparse:
                self.save_sparse(saveas)
            else:
                self.save_non_sparse(saveas)
            self.toggleBusy()
        elif symbol == key.X:
            self.toggleBusy()
            if sync:
                sync = False
            else:
                sync = True
            self.update_all_windows()
            self.toggleBusy()
        # skip to next marked point
        elif symbol == key.RIGHT:
            for k in range(self.current_point_index, self.points[current_track_global].shape[0]):
                if np.all(self.points[current_track_global][k].toarray()[0] != 0):
                    self.current_point_index = k + 1
                    current_frame = self.current_point_index
                    self.change_marker()
                    if sync:
                        self.update_all_windows()
                    self.changed = True
                    break
        # skip to previously marked point
        elif symbol == key.LEFT:
            for k in range(2, self.current_point_index):
                if np.all(self.points[current_track_global][self.current_point_index - k].toarray()[0] != 0):
                    self.current_point_index = self.current_point_index - k + 1
                    current_frame = self.current_point_index
                    self.change_marker()
                    if sync:
                        self.update_all_windows()
                    self.changed = True
                    break
        elif symbol == key.UP:
            # if not self.base:
            self.frameFinder.offset = self.frameFinder.offset + 1
            self.changed = True
            current_frame = self.current_point_index
            self.change_marker()
            if sync:
                self.update_all_windows()

        elif symbol == key.DOWN:
            # if not self.base:
            self.frameFinder.offset = self.frameFinder.offset - 1
            self.changed = True
            current_frame = self.current_point_index
            self.change_marker()
            if sync:
                self.update_all_windows()

        elif symbol == key.I:
            if vx - 1 >= 5:
                vx -= 1
        elif symbol == key.Y:
            if vx + 1 <= 30:
                vx += 1
        elif symbol == key.U:
            if vy - 1 >= 5:
                vy -= 1
        elif symbol == key._7:
            if vy + 1 <= 30:
                vy += 1

        # clearing all tracks from the current window
        elif symbol == key.C and (modifiers == 0 or modifiers == 16):
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = YesNoPopup(f"Clear all tracks for camera {self.actual_camera_number}. Are you sure?")
            if w.exec() == QtWidgets.QDialog.Accepted:
                if w.reply == 'Yes':
                    self.points = dict()
                    self.clearBatch()
                    self.update_tracks()
        elif symbol == key.D and modifiers & key.MOD_SHIFT:
            if len(track_list_global) > 1:
                app = QtWidgets.QApplication.instance()
                if app is None:
                    app = QtWidgets.QApplication([])
                w = YesNoPopup(f"Delete track {current_track_global}. Are you sure?")
                if w.exec() == QtWidgets.QDialog.Accepted:
                    if w.reply == 'Yes':
                        old_track = current_track_global
                        track_list_global.remove(current_track_global)
                        if len(track_list_global) != 0:
                            current_track_global = track_list_global[0]
                        # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                        for window in pyglet.app.windows:
                            if isinstance(window, ClickerWindow):
                                window.change_track(old_track)
                                window.deleteTrack(old_track)
                        self.update_all_windows()
            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Cannot delete track, must have at least one track to work with. Please add add a new track before deleting this one."
                )
            # self.trackingColors = list()
        # loading points from a CSV file
        elif symbol == key.L:
            self.toggleBusy()
            app = QtWidgets.QApplication.instance()
            if app is None:
                app = QtWidgets.QApplication([])
            w = OpenFilePopup("Select _xypts.csv file", str(self.movie).split('/')[0],'CSV (*xypts.csv)')
            if w.filename:
                filename = w.filename
                if type(filename) == str:
                    if filename != '' and filename.split('.')[-1] == 'csv':
                        load_csv(filename) #creates load_data_global as a csc_matrix for all points (shape of csv)

                    elif filename != '' and filename.split('.')[-1] == 'tsv':
                        outputSparse = True

                        load_tsv(filename)

            if load_data_global is not None:
                offsetMatches = list()
                # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
                for window in pyglet.app.windows:
                    if isinstance(window, ClickerWindow):
                        window.points = dict()
                        window.update_tracks() # gives points its track names as keys and each value as empty csc_matrix with shape of rows = frames and 2 cols
                        offsetMatches.append(window.load_points()) # assigns values to points from load_data_global
                        # on load, load_data_global is a csc_matrix, but the assignment uses normal indexing
                        window.updateSelf()
                if False in offsetMatches:
                    QtWidgets.QMessageBox.warning(None,
                        "Warning",
                        "Offsets may be wrong. There are more frames in the loaded CSV than there are in the first camera"
                    )

                load_data_global = None
            self.toggleBusy()
        # delete the point in the current frame and track
        elif symbol == key.D and (modifiers == 0 or modifiers == 16):
            positions = copy.copy(self.points[current_track_global])
            positions[self.current_point_index - 1] = np.asarray([0., 0.])
            positions.eliminate_zeros()
            self.points[current_track_global] = positions
            self.delete_point()
        # plot 3D tracks if we have dlt coefficients and camera profile
        elif symbol == key.P:
            self.toggleBusy()
            # if we have DLT coefficients and intrinsic camera information,
            # triangulate and write the 3D coordinates frame-by-frame
            if DLTCoefficients is not None and camera_profile is not None:
                self.plotTracks()
                # self.plotTracks(track_indices=np.arange(len(track_list_global)))
            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Must have DLT coefficients and a camera profile to obtain 3D coordinates"
                )
            self.toggleBusy()
        elif symbol == key.P and modifiers & key.MOD_CTRL:
            self.toggleBusy()
            if DLTCoefficients is not None and camera_profile is not None:
                self.plotTracks(track_indices=[track_list_global.index(current_track_global)])
            else:
                QtWidgets.QMessageBox.warning(None,
                    "Error",
                    "Must have DLT coefficients and a camera profile to obtain 3D coordinates"
                )
            self.toggleBusy()

    def on_mouse_press(self, x, y, buttons, modifiers):
        global sync
        global auto_advance
        global track_list_global
        global current_track_global
        global current_frame

        if buttons & mouse.LEFT:
            if current_track_global != '' and (modifiers == 16 or modifiers == 0):
                self.draw_new_point(float(x) / self.width * self.zoomed_width + self.left,
                                    float(y) / self.height * self.zoomed_height + self.bottom)
                if auto_advance:
                    im = self.frameFinder.getFrame(self.current_point_index + 1)
                    if im is not None and self.current_point_index + 1 <= self.end:
                        self.changed = True
                        self.current_point_index += 1
                        self.change_marker()
                        current_frame = self.current_point_index
                        if sync:
                            self.update_all_windows()
            elif modifiers & key.MOD_CTRL:
                self.trackingColors.append(self.frameFinder.getColor(np.asarray(
                    [float(x) / self.width * self.zoomed_width + self.left,
                     float(y) / self.height * self.zoomed_height + self.bottom])))

        elif buttons & mouse.RIGHT:
            positions = copy.copy(self.points[current_track_global])
            positions[self.current_point_index - 1] = np.asarray([0., 0.])
            positions.eliminate_zeros()
            self.points[current_track_global] = positions
            self.delete_point()



    def on_mouse_motion(self, x, y, dx, dy):
        self.x = float(x) / self.width * self.zoomed_width + self.left
        self.y = self.frameFinder.oh - (float(y) / self.height * self.zoomed_height + self.bottom)
        # if self.show_view:
        #     self.viewfinder_window.clear()
        #     self.update_viewfinder()

class TrackPlotter(QtWidgets.QWidget):
    def __init__(self, pts, track_indices, camera_profile, DLTcoefficients, ArgusColors):
        super().__init__()
        self.pts = pts
        self.track_indices = track_indices
        self.camera_profile = camera_profile
        self.DLTCoefficients = DLTCoefficients
        self.colors = ArgusColors().getPygletColors()
        self.xyzss = self.calculate_xyzs()
        
    def init_UI(self):
        main_layout = QtWidgets.QVBoxLayout()
        self.view = pyqt_gl.GLViewWidget()
        self.view.setWindowTitle('3D Graph')
        self.view.setCameraPosition(distance=20)
        # Create grid items for better visualization
        self.grid = pyqt_gl.GLGridItem()
        self.grid.scale(2, 2, 1)
        self.view.addItem(self.grid)
        # Add x, y, z axes lines
        axis_length = 10
        self.x_axis = pyqt_gl.GLLinePlotItem(pos=np.array([[0, 0, 0], [axis_length, 0, 0]]), color=(1, 0, 0, 1), width=2)  # Red line for x-axis
        self.y_axis = pyqt_gl.GLLinePlotItem(pos=np.array([[0, 0, 0], [0, axis_length, 0]]), color=(0, 1, 0, 1), width=2)  # Green line for y-axis
        self.z_axis = pyqt_gl.GLLinePlotItem(pos=np.array([[0, 0, 0], [0, 0, axis_length]]), color=(0, 0, 1, 1), width=2)  # Blue line for z-axis
        self.view.addItem(self.x_axis)
        self.view.addItem(self.y_axis)
        self.view.addItem(self.z_axis)
        main_layout.addWidget(self.view)
        self.setLayout(main_layout)
        self.resize(800, 800)
        self.updateGraph()
        
    def calculate_xyzs(self):
        xyzss = []
        for j in range(int(self.pts.shape[1] / (2 * len(self.camera_profile)))):
            xyzs = uv_to_xyz(self.pts[:, j * 2 * len(self.camera_profile):(j + 1) * 2 * len(self.camera_profile)], self.camera_profile, self.DLTCoefficients)
            xyzss.append(xyzs)
        return xyzss
        
    def updateGraph(self):
        self.view.clear()
        # Re-add grid and axes
        self.view.addItem(self.grid)
        self.view.addItem(self.x_axis)
        self.view.addItem(self.y_axis)
        self.view.addItem(self.z_axis)
        # plot here
        # Plot each track
        for k in range(len(self.track_indices)):
            xyz = self.xyzss[self.track_indices[k]]
            plotxyz = np.array(xyz).reshape(-1,3)
            color = self.colors[k % len(self.colors)]
            color = (color[0]/255.0, color[1]/255.0, color[2]/255.0, 1)
            
            scatter = pyqt_gl.GLScatterPlotItem(pos = plotxyz, color=color, size=20)
            
            scatter.setGLOptions('translucent')
            self.view.addItem(scatter)


class ATrackPlotter(pyglet.window.Window):
    def __init__(self, pts, track_indices, camera_profile, DLTCoefficients, ArgusColors):
        super(TrackPlotter, self).__init__(width=800, height=600, caption="Track Plotter", resizable=True)
        self.pts = pts
        self.track_indices = track_indices
        self.camera_profile = camera_profile
        self.DLTCoefficients = DLTCoefficients
        self.colors = ArgusColors().getPygletColors()
        self.xyzss = self.calculate_xyzs()
        
        # Set up OpenGL context
        glEnable(GL_DEPTH_TEST)
        glClearColor(0.0, 0.0, 0.0, 1.0)
        
        # Rotation state
        self.rot_x = 0
        self.rot_y = 0
        self.mouse_x = 0
        self.mouse_y = 0
        
        # Zoom state
        self.zoom = -40
        
    def calculate_xyzs(self):
        xyzss = []
        for j in range(int(self.pts.shape[1] / (2 * len(self.camera_profile)))):
            xyzs = uv_to_xyz(self.pts[:, j * 2 * len(self.camera_profile):(j + 1) * 2 * len(self.camera_profile)], self.camera_profile, self.DLTCoefficients)
            xyzss.append(xyzs)
        return xyzss

    def setup_projection(self):
        # glMatrixMode(GL_PROJECTION)
        glLoadIdentity()
        gluPerspective(45.0, self.width / self.height, 0.1, 100.0)
        # glMatrixMode(GL_MODELVIEW)
        glLoadIdentity()
        
    def plot_grid(self):
        glColor3f(0.5, 0.5, 0.5)  # Gray color for grid
        glBegin(GL_LINES)
        grid_size = 10
        for i in range(-grid_size, grid_size + 1):
            glVertex3f(i, -grid_size, 0)
            glVertex3f(i, grid_size, 0)
            glVertex3f(-grid_size, i, 0)
            glVertex3f(grid_size, i, 0)
        glEnd()
        
    def plot_axes(self):
        axis_length = 10
        glLineWidth(2.0)  # Set line width for axes
        glBegin(GL_LINES)

        # X axis (Red)
        glColor3f(1.0, 0.0, 0.0)
        glVertex3f(0, 0, 0)
        glVertex3f(axis_length, 0, 0)

        # Y axis (Green)
        glColor3f(0.0, 1.0, 0.0)
        glVertex3f(0, 0, 0)
        glVertex3f(0, axis_length, 0)

        # Z axis (Blue)
        glColor3f(0.0, 0.0, 1.0)
        glVertex3f(0, 0, 0)
        glVertex3f(0, 0, axis_length)
        
        glEnd()
        glLineWidth(1.0)
        
    def plot_tracks(self):
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
        # glLoadIdentity()

        # Apply rotations
        glTranslatef(0, 0, self.zoom)
        glRotatef(self.rot_x, 1, 0, 0)
        glRotatef(self.rot_y, 0, 1, 0)

        # Plot grid on XY plane
        self.plot_grid()

        # Plot axes 
        self.plot_axes()
        
        # Plot each track
        for k in range(len(self.track_indices)):
            xyz = self.xyzss[self.track_indices[k]]
            # xyz = xyz[~np.isnan(xyz).any(axis=1)]
            # if xyz.size == 0:  # Skip if xyz is empty after filtering
            #     continue
            x = xyz[:, 0]
            y = xyz[:, 1]
            z = xyz[:, 2]
            color = self.colors[k % len(self.colors)]
            glColor3f(color[0]/255.0, color[1]/255.0, color[2]/255.0)
            glBegin(GL_LINE_STRIP)
            for i in range(len(x)):
                glVertex3f(x[i], y[i], z[i])
            glEnd()
            self.plot_spheres(x, y, z, color)
            
    def plot_spheres(self, x, y, z, color):
        quadric = gluNewQuadric()
        glColor3f(color[0]/255.0, color[1]/255.0, color[2]/255.0)
        for i in range(len(x)):
            glPushMatrix()
            glTranslatef(x[i], y[i], z[i])
            gluSphere(quadric, 0.2, 4, 4)  # Radius of 0.2, 4 slices, 4 stacks
            glPopMatrix()
        gluDeleteQuadric(quadric)
        
    def on_draw(self):
        self.setup_projection()
        self.plot_tracks()
        self.draw_labels()
        
    def on_mouse_drag(self, x, y, dx, dy, buttons, modifiers):
        self.rot_x += dy * 0.5
        self.rot_y += dx * 0.5

    def on_mouse_press(self, x, y, button, modifiers):
        self.mouse_x = x
        self.mouse_y = y

    def on_mouse_release(self, x, y, button, modifiers):
        self.mouse_x = 0
        self.mouse_y = 0
        
    def on_mouse_scroll(self, x, y, scroll_x, scroll_y):
        self.zoom += scroll_y * 2  # Adjust zoom speed
        
    def draw_labels(self):
        # Draw axis labels
        self.draw_text("X", 1.0, 0.0, 0.0, (1.0, 0.0, 0.0, 1.0))
        self.draw_text("Y", 0.0, 1.0, 0.0, (0.0, 1.0, 0.0, 1.0))
        self.draw_text("Z", 0.0, 0.0, 1.0, (0.0, 0.0, 1.0, 1.0))

    def draw_text(self, text, x, y, z, color):
        label = pyglet.text.Label(text,
                                  font_name='Times New Roman',
                                  font_size=24,
                                  color=(int(color[0]*255), int(color[1]*255), int(color[2]*255), int(color[3]*255)),
                                  x=0, y=0,
                                  anchor_x='center', anchor_y='center')
        glPushMatrix()
        glTranslatef(x, y, z)
        glScalef(0.02, 0.02, 0.02)  # Scale the text to fit the 3D plot
        label.draw()
        glPopMatrix()
        
# function scheduled everytime autotracking is turned on
# to create a loop. it is unscheduled when autotracking is turned off
def up(dt):
    # for window in [u for u in pyglet.app.windows if type(u) != GhostWindow]:
    for window in pyglet.app.windows:
        if isinstance(window, ClickerWindow):
            window.tick()
    # time.sleep(0.1)


# checks if there are other windows besides the Ghost Window
def check_to_close(dt):
    windows = [u for u in pyglet.app.windows]
    if len(windows) == 1:
        if type(windows[0]) == GhostWindow:
            windows[0].close()


# ghost window by Ty
class GhostWindow(pyglet.window.Window):
    def __init__(self):
        super(GhostWindow, self).__init__(width=10, height=10, visible=False, resizable=False)


def parse_csv(csv: str) -> lil_matrix:
    """Parses a csv file for a point matrix as formatted by argus
    :param csv: A path to a .csv file
    :return: a scipy lil_matrix with points like:
        [
            [cam1_x_track_1, cam1_y_track_1, cam2_x_track_1, cam2_y_track_1, ...., camN_x_track_1, camN_x_track_2]
            .
            .
            .
            [...]
        ]
        where each row represents a frame number corresponding to the original video
    """
    if csv.split('.')[-1] == 'csv':
        dataf = pandas.read_csv(csv, index_col=False)
        return dataf.values
    # else check if we have sparse data representation
    elif csv.split('.')[-1] == 'tsv':
        fo = open(csv)
        # expect a header
        line = fo.readline()
        # next line has shape information for the sparse matrix
        line = fo.readline()
        shape = list(map(int, line.split('\t')))
        # ret = lil_matrix((shape[0], shape[1]))
        ret = lil_matrix((shape[0], shape[1]))
        ret[:, :] = np.nan
        line = fo.readline()
        while line != '':
            val = list(map(float, line.split('\t')))
            ret[int(val[0]) - 1, int(val[1]) - 1] = val[2]
            line = fo.readline()
        return ret


def check_if_file(path):
    if path is None: return
    if not os.path.isfile(path):
        app = QtWidgets.QApplication.instance()
        if app is None:
            app = QtWidgets.QApplication([])
        QtWidgets.QMessageBox.warning(None,
            "Error",
            f"Unable to locate {path}"
        )
        return False

    else: return True


def load_settings(settings):
    global sync
    global displaying_all_tracks
    global current_track_global
    global auto_advance
    global global_filename
    global rgb
    global outputSparse
    global bstrap

    sync = settings["sync"]
    displaying_all_tracks = settings["displaying_all_tracks"]
    current_track_global = settings["current_track"]
    auto_advance = settings["auto_advance"]
    global_filename = settings["global_filename"]
    rgb = settings["rgb"]
    outputSparse = settings["output_sparse"]
    bstrap = settings["bstrap"]


def load_from_config(path):
    global movies_global
    global DLTCoefficients
    global dlt_filename

    with open(path) as f:
        project = yaml.load(f, Loader=yaml.FullLoader)

    project_videos = project[0]

    project_points = project[1]
    if not check_if_file(project_points["points"]): return

    project_resultion = project[2]
    project_last_frame = project[3]

    project_offsets = project[4]
    if not check_if_file(project_offsets["offsets"]): return
    loaded_offsets = project_offsets["offsets"]

    frame_number = project_last_frame["last_frame"]
    loaded_res = project_resultion["resolution"]

    loaded_movies = project_videos["videos"]
    movies_global = loaded_movies

    loaded_offsets = parse_csv(loaded_offsets)
    useable_offsets = []

    dlt_coeff = project[5]
    dlt_path = dlt_coeff["dlt_coefficents"]
    if check_if_file(dlt_path):
        DLTCoefficients = np.loadtxt(dlt_path, delimiter=',')
        DLTCoefficients = DLTCoefficients.T
        dlt_filename = dlt_path

    camera_profile = project[6]
    camera_profile_path = camera_profile["camera_profile"]
    if check_if_file(camera_profile_path):
        load_camera(camera_profile_path)

    for camera_index in range(0, len(loaded_movies)):
        offset = loaded_offsets[frame_number - 2][camera_index]
        if np.isnan(offset):
            offset = 0
        useable_offsets.append(offset)

    loaded_end = int(cv2.VideoCapture(loaded_movies[0]).get(cv2.CAP_PROP_FRAME_COUNT))

    windows = []
    for index, movie in enumerate(loaded_movies):
        if not check_if_file(movie): return
        if index != len(loaded_movies) - 1:
            mov = ClickerWindow(movie, offsets=useable_offsets, actual_camera_number=index + 1, end=loaded_end,
                              factor=loaded_res)
            mov.go_to_frame(frame_number)

            windows.append(mov)

        else:
            mov = ClickerWindow(movie, offsets=useable_offsets, actual_camera_number=index + 1, end=loaded_end,
                                         factor=loaded_res,
                                         last=True)
            mov.go_to_frame(frame_number)
            windows.append(mov)

    load_csv(project_points["points"])
    
    settings = project[7]["settings"]
    load_settings(settings)
    
    if sys.platform == 'win32':
        pyglet.clock.schedule_once(check_to_close, .5)

    def update_after(_):
        indexable_windows = [u for u in windows if type(u) != GhostWindow]
        if load_data_global is not None:
            offsetMatches = list()
            for window in indexable_windows:
                window.points = dict()
                window.update_tracks()
                offsetMatches.append(window.load_points())
                window.updateSelf()

        indexable_windows[0].change_track(settings["init_track"])
        indexable_windows[0].update_all_windows()

        for window in indexable_windows:
            window.switch_to()
            window.update_tracks()
            window.dispatch_events()
            window.dispatch_event('on_draw')
            window.flip()

            window.frameFinder.rgb = rgb
            im = window.frameFinder.getFrame(window.current_point_index)
            if im is not None:
                window.img = pyglet.sprite.Sprite(ArrayInterfaceImage(im).get_texture())
                window.img.scale = float(window.scale_factor)
                
    pyglet.clock.schedule_once(update_after, .05)
    pyglet.app.run()


if __name__ == '__main__':
    movies_global = None
    # start a QT app for warning dialogs at least
    app = QtWidgets.QApplication.instance()
    if app is None:
        app = QtWidgets.QApplication([])
        
    if sys.argv[1].startswith("configload@"):
        load_from_config(sys.argv[1].split("@")[1])

    else:
        end = int(sys.argv[2])
        movies_global = sys.argv[1].split('@')

        movies = movies_global
        offsets = list(map(int, sys.argv[3].split('@')))
        factor = int(sys.argv[4])

        windows = []
        for index, movie in enumerate(movies):
            if index != len(movies) - 1:
                curWindow = ClickerWindow(movie, offsets=offsets, actual_camera_number=index + 1, end=end, factor=factor)
                windows.append(curWindow)
                if offsets[index] != 0 and offsets[index] < 0:
                    curWindow.go_to_frame(1 + np.abs(offsets[index]))
            else:
                curWindow = ClickerWindow(movie, offsets=offsets, actual_camera_number=index + 1, end=end, factor=factor,
                                          last=True)

                windows.append(curWindow)
                if offsets[index] != 0 and offsets[index] < 0:       
                    curWindow.go_to_frame(1 + np.abs(offsets[index]))

        if sys.platform == 'win32':
            pyglet.clock.schedule_once(check_to_close, .5)

        pyglet.app.run()
